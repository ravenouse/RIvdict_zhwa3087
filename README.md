# Revdict_zhwa3087

## General

This repo is to describe our experiments and store our codes to proceed with the Reverse Dictionary Task, which
is one of the two tracks of [SemEval 2022 Task 1](https://competitions.codalab.org/competitions/34022).<br>

Our Paper has been submitted to the SemEval2022 on Feb 28th 2022. The link to the current version of our paper: [Zhwa3087 at Semeval-2022 Task 1](https://drive.google.com/file/d/1g8975sB83w-Q4EUkH3uPUnjPswCA10vp/view?usp=sharing).<br>

All our models' codes are adapted from and inspired by [organizers' baseline code](https://github.com/TimotheeMickus/codwoe/tree/main/code). <br>
We want to express our thanks to the organizers here again for their effort.<br>

## Links to different versions of our code.

### Monolingual
Our [RNN-based Monolingual Model](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Monolingual-RNN-based-Model) <br>

Our [BiRNN-based Monolingual Model](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Monolingual-BiRNN-based-Model) <br>

Our [LSTM-based Monolingual Model](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Monolingual-LSTM-based-Model) <br>

Our [Elmo-based Monolingual Model](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Monolingual-Elmo-based-Model) <br>

Our [Transformer-based Monolingual Model](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Monolingual-Transformer-based-Model) <br>


### Multilingual

#### Transformer-based
Our [Multilingual-Transformer-based-Model](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Multilingual-Transformer-based-Model) <br>

Our [Multilingual-Transformer-based-Model(RC)](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Multilingual-Transformer-based-Model(RC)) <br>

Our [Multilingual-Transformer-based-Model(ALT)](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Multilingual-Transformer-based-Model(ALT))) <br>

Our [Multilingual-Transformer-based-Model(RC+ALT)](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Multilingual-Transformer-based-Model(RC+ALT))) <br>

#### Elmo-based
Our [Elmo-based Monolingual Model](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Multilingual-Elmo-based-Model)<br>

Our [Elmo-based Monolingual Model(ALT)](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Multilingual-Elmo-based-Model(ALT))<br>

### Multitask
Our [ELMO-based Monolingual Multitask model with DWA optimization](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Monolingual-Multitask-ELMO-based-Model(DWA))<br>

## Others
[Tokenizers](https://github.com/ravenouse/Revdict_ZHWA3087/tree/Tokenizers) that we have used in the experiments <br>

[Other Python code](https://github.com/ravenouse/Revdict_ZHWA3087) that we have used in the experiments<br>
